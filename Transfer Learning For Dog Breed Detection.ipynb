{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I break the notebook into separate steps. \n",
    "* [Step 1](#step1): Import Datasets\n",
    "* [Step 2](#step2): Create ensembled features using Resnet50, Xception, and InceptionV3\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (using Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Import Datasets\n",
    "\n",
    "### Import Dog Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6144,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Create ensembled features using Resnet50, Xception, and InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# features created by the deep convolutional layers of Resnet50 \n",
    "bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')\n",
    "train_Resnet50 = bottleneck_features['train']\n",
    "valid_Resnet50 = bottleneck_features['valid']\n",
    "test_Resnet50 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# features created by the deep convolutional layers of InceptionV3\n",
    "bottleneck_features = np.load('bottleneck_features/DogInceptionV3Data.npz')\n",
    "train_InceptionV3 = bottleneck_features['train']\n",
    "valid_InceptionV3 = bottleneck_features['valid']\n",
    "test_InceptionV3 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# features created by the deep convolutional layers of Xception\n",
    "bottleneck_features = np.load('bottleneck_features/DogXceptionData.npz')\n",
    "train_Xception = bottleneck_features['train']\n",
    "valid_Xception = bottleneck_features['valid']\n",
    "test_Xception = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_13  (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 0.0\n",
      "Trainable params: 0.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# transfer 4d matrix to 2d\n",
    "InceptionV3_flatten_model = Sequential()\n",
    "InceptionV3_flatten_model.add(GlobalAveragePooling2D(input_shape=train_InceptionV3.shape[1:]))\n",
    "InceptionV3_flatten_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_14  (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 0.0\n",
      "Trainable params: 0.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# transfer 4d matrix to 2d\n",
    "Xception_flatten_model = Sequential()\n",
    "Xception_flatten_model.add(GlobalAveragePooling2D(input_shape=train_Xception.shape[1:]))\n",
    "Xception_flatten_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_15  (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 0.0\n",
      "Trainable params: 0.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# transfer 4d matrix to 2d\n",
    "Resnet50_flatten_model = Sequential()\n",
    "Resnet50_flatten_model.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))\n",
    "Resnet50_flatten_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transfer 4d matrix to 2d\n",
    "train_InceptionV3 = InceptionV3_flatten_model.predict(train_InceptionV3)\n",
    "valid_InceptionV3 = InceptionV3_flatten_model.predict(valid_InceptionV3)\n",
    "test_InceptionV3 = InceptionV3_flatten_model.predict(test_InceptionV3)\n",
    "\n",
    "train_Xception = Xception_flatten_model.predict(train_Xception)\n",
    "valid_Xception = Xception_flatten_model.predict(valid_Xception)\n",
    "test_Xception = Xception_flatten_model.predict(test_Xception)\n",
    "\n",
    "train_Resnet50 = Resnet50_flatten_model.predict(train_Resnet50)\n",
    "valid_Resnet50 = Resnet50_flatten_model.predict(valid_Resnet50)\n",
    "test_Resnet50 = Resnet50_flatten_model.predict(test_Resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_feature = np.concatenate((train_InceptionV3, train_Xception, train_Resnet50), axis=1)\n",
    "valid_feature = np.concatenate((valid_InceptionV3, valid_Xception, valid_Resnet50), axis=1)\n",
    "test_feature = np.concatenate((test_InceptionV3, test_Xception, test_Resnet50), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6144,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (using Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 1024)              6292480   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 6,885,509.0\n",
      "Trainable params: 6,885,509.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dense layer model using the ensembled features from three DCN\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=train_feature.shape[1:]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Compile the model.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      "Epoch 00000: val_acc improved from -inf to 0.79521, saving model to saved_models/weights.best.model1.hdf5\n",
      "15s - loss: 2.3075 - acc: 0.4754 - val_loss: 0.6509 - val_acc: 0.7952\n",
      "Epoch 2/20\n",
      "Epoch 00001: val_acc improved from 0.79521 to 0.85749, saving model to saved_models/weights.best.model1.hdf5\n",
      "6s - loss: 0.6304 - acc: 0.8129 - val_loss: 0.4886 - val_acc: 0.8575\n",
      "Epoch 3/20\n",
      "Epoch 00002: val_acc improved from 0.85749 to 0.88623, saving model to saved_models/weights.best.model1.hdf5\n",
      "6s - loss: 0.4019 - acc: 0.8702 - val_loss: 0.4057 - val_acc: 0.8862\n",
      "Epoch 4/20\n",
      "Epoch 00003: val_acc did not improve\n",
      "6s - loss: 0.2990 - acc: 0.9058 - val_loss: 0.3922 - val_acc: 0.8743\n",
      "Epoch 5/20\n",
      "Epoch 00004: val_acc did not improve\n",
      "6s - loss: 0.2264 - acc: 0.9229 - val_loss: 0.4442 - val_acc: 0.8731\n",
      "Epoch 6/20\n",
      "Epoch 00005: val_acc did not improve\n",
      "6s - loss: 0.1772 - acc: 0.9448 - val_loss: 0.4057 - val_acc: 0.8814\n",
      "Epoch 7/20\n",
      "Epoch 00006: val_acc did not improve\n",
      "6s - loss: 0.1335 - acc: 0.9570 - val_loss: 0.4331 - val_acc: 0.8647\n",
      "Epoch 8/20\n",
      "Epoch 00007: val_acc did not improve\n",
      "6s - loss: 0.1121 - acc: 0.9651 - val_loss: 0.4464 - val_acc: 0.8695\n",
      "Epoch 9/20\n",
      "Epoch 00008: val_acc did not improve\n",
      "6s - loss: 0.0890 - acc: 0.9714 - val_loss: 0.4311 - val_acc: 0.8838\n",
      "Epoch 10/20\n",
      "Epoch 00009: val_acc improved from 0.88623 to 0.89222, saving model to saved_models/weights.best.model1.hdf5\n",
      "6s - loss: 0.0698 - acc: 0.9766 - val_loss: 0.4587 - val_acc: 0.8922\n",
      "Epoch 11/20\n",
      "Epoch 00010: val_acc improved from 0.89222 to 0.89461, saving model to saved_models/weights.best.model1.hdf5\n",
      "6s - loss: 0.0624 - acc: 0.9796 - val_loss: 0.4402 - val_acc: 0.8946\n",
      "Epoch 12/20\n",
      "Epoch 00011: val_acc did not improve\n",
      "6s - loss: 0.0512 - acc: 0.9840 - val_loss: 0.4693 - val_acc: 0.8838\n",
      "Epoch 13/20\n",
      "Epoch 00012: val_acc did not improve\n",
      "6s - loss: 0.0483 - acc: 0.9864 - val_loss: 0.4586 - val_acc: 0.8886\n",
      "Epoch 14/20\n",
      "Epoch 00013: val_acc did not improve\n",
      "6s - loss: 0.0403 - acc: 0.9882 - val_loss: 0.4841 - val_acc: 0.8814\n",
      "Epoch 15/20\n",
      "Epoch 00014: val_acc did not improve\n",
      "6s - loss: 0.0307 - acc: 0.9912 - val_loss: 0.4869 - val_acc: 0.8766\n",
      "Epoch 16/20\n",
      "Epoch 00015: val_acc did not improve\n",
      "6s - loss: 0.0375 - acc: 0.9891 - val_loss: 0.5039 - val_acc: 0.8838\n",
      "Epoch 17/20\n",
      "Epoch 00016: val_acc did not improve\n",
      "7s - loss: 0.0315 - acc: 0.9900 - val_loss: 0.4626 - val_acc: 0.8922\n",
      "Epoch 18/20\n",
      "Epoch 00017: val_acc did not improve\n",
      "6s - loss: 0.0326 - acc: 0.9916 - val_loss: 0.4813 - val_acc: 0.8826\n",
      "Epoch 19/20\n",
      "Epoch 00018: val_acc did not improve\n",
      "6s - loss: 0.0317 - acc: 0.9900 - val_loss: 0.4619 - val_acc: 0.8922\n",
      "Epoch 20/20\n",
      "Epoch 00019: val_acc improved from 0.89461 to 0.89581, saving model to saved_models/weights.best.model1.hdf5\n",
      "6s - loss: 0.0258 - acc: 0.9931 - val_loss: 0.4865 - val_acc: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6c047dce10>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train the model and save the prameters of the model with the best performance in validation set\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.model1.hdf5', monitor='val_acc',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_feature, train_targets, \n",
    "          validation_data=(valid_feature, valid_targets),\n",
    "          epochs=20, batch_size=400, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88.8756%\n"
     ]
    }
   ],
   "source": [
    "### Calculate classification accuracy on the test dataset.\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in test_feature]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image  \n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "import os\n",
    " \n",
    "# METHOD #1: OpenCV, NumPy, and urllib\n",
    "def url_to_tensor(url):\n",
    "    # download the image, convert it to a NumPy array, and then read\n",
    "    urllib.request.urlretrieve(url, 'img_buf.jpg')\n",
    "    tensor = path_to_tensor('img_buf.jpg')\n",
    "    os.remove('img_buf.jpg')\n",
    "    # return the image\n",
    "    return tensor\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'https://i.amz.mshcdn.com/K47URRdccsvcDhyc1IpfrQ0WN9s=/1200x630/2017%2F08%2F11%2Ff2%2Ffda8c2c1913a45bab33a5e04b897cb9b.4021f.jpg'\n",
    "img = url_to_tensor(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "def model_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    Resnet50_feature = extract_Resnet50(path_to_tensor(img_path))\n",
    "    InceptionV3_feature = extract_InceptionV3(path_to_tensor(img_path))\n",
    "    Xception_feature = extract_Xception(path_to_tensor(img_path))\n",
    "    \n",
    "    InceptionV3_feature = InceptionV3_flatten_model.predict(InceptionV3_feature)\n",
    "    Xception_feature = Xception_flatten_model.predict(Xception_feature)\n",
    "    Resnet50_feature = Resnet50_flatten_model.predict(Resnet50_feature)\n",
    "\n",
    "    feature = np.concatenate((InceptionV3_feature, Xception_feature, Resnet50_feature), axis=1)\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = model.predict(feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Havanese'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict_breed('test\\\\damon.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Old_english_sheepdog'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict_breed('test\\\\gumu.jpg')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind-dl]",
   "language": "python",
   "name": "conda-env-aind-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
